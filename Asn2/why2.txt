2 Why Questions
--------------------------------
1. The before value of the 4th point is non-zero because that value has already been seen once before. The X value in sample 2 and sample 4 are identical; therefore some learning about that state has already happened by the time it is seen for the second time. 


2. The MSE comes down smoothly from 0.25 to 0.01, and then stays there. It does not further decrease because the state spaces are being generalized. This means that the machine can't learn the best thing to do in EVERY state, but only the best thing to do in most states. Because of this, it will always be wrong some of the time.



Paragraph:

The final learned function after 10000 iterations has 3 main peaks, and 3 main troughs. 
Our learned function after only 20 iterations also has 3 peaks and 3 troughs, though they aren't nearly as wide and tall, they will become so after more iterations. The heights in the first (the shorter) learning are abour 2/3's what they will be in the second learning. The widths are about half what they will become in the second learning.

If the tiling was input space was changed to 11x21, with the x dimension being divided twice as finely as the y dimension, the function would produce less error in the x dimension that in the y dimension. Because of this, the plot would look a little lopsided, being wider in the X dimension than the y dimension. 